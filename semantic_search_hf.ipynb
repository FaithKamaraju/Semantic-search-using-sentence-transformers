{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/faith/pythonenvs/nlpia_env/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from datasets import load_dataset, Dataset\n",
    "import re\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "from transformers import AutoTokenizer, AutoModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.set_default_device('cuda')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading the godot docs and cleaning the .rst files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def clean_rst(content):\n",
    "    # with open(file_path, 'r', encoding='utf-8') as f:\n",
    "    #     content = f.read()\n",
    "\n",
    "    # Remove directives (e.g., .. image::, .. note::)\n",
    "    content = re.sub(r\"\\.\\. [^\\n]*::[^\\n]*(\\n +[^\\n]*)*\", \"\", content)\n",
    "\n",
    "    # Remove inline roles (e.g., :ref:`label`)\n",
    "    content = re.sub(r\":[a-zA-Z0-9]+:`([^`]*)`\", r\"\\1\", content)\n",
    "\n",
    "    # Remove hyperlinks (e.g., `text <url>`_)\n",
    "    content = re.sub(r\"`([^`]+) <[^>]+>`_\", r\"\\1\", content)\n",
    "\n",
    "    # Remove substitution references (e.g., |substitution|)\n",
    "    content = re.sub(r\"\\|[^|]+\\|\", \"\", content)\n",
    "\n",
    "    # Remove comments (e.g., .. this is a comment)\n",
    "    content = re.sub(r\"\\.\\. .*\\n\", \"\", content)\n",
    "        \n",
    "    # Remove segmentation symbols\n",
    "    content = re.sub(r'[~=-]+',\"\",content)\n",
    "    \n",
    "    # Remove excessive blank lines\n",
    "    content = re.sub(r\"\\n{3,}\", \"\\n\", content)\n",
    "\n",
    "    return content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from os import listdir\n",
    "from os.path import isfile, join\n",
    "mypath = \"godot_docs/\"\n",
    "files = [mypath+f for f in listdir(mypath) if isfile(join(mypath, f))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus = []\n",
    "for file in files:\n",
    "    with open(file,encoding=\"utf8\") as f:\n",
    "        doc = f.read()\n",
    "    cleaned_doc = clean_rst(doc)\n",
    "    corpus.append(cleaned_doc)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "filenames = [re.sub(r\"godot_docs/\",\"\",file) for file in files]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = pd.DataFrame.from_dict({'File':filenames,'document':corpus})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Setting up the project\n",
      "In this short first part, we'll set up and organize the project.\n",
      "\n",
      "Launch Godot and create a new project.\n",
      "When creating the new project, you only need to choose a valid *Project Path*. You can leave the other default settings alone.\n",
      "    Download dodge_the_creeps_2d_assets.zip.\n",
      "    The archive contains the images and sounds you'll be using\n",
      "    to make the game. Extract the archive and move the ``art/``\n",
      "    and ``fonts/`` directories to your project's directory.\n",
      "\n",
      " \n",
      "\n",
      "    Download dodge_the_creeps_2d_assets.zip.\n",
      "    The archive contains the images and sounds you'll be using\n",
      "    to make the game. Extract the archive and move the ``art/``\n",
      "    and ``fonts/`` directories to your project's directory.\n",
      "\n",
      "    Ensure that you have the required dependencies to use C# in Godot.\n",
      "    You need the latest stable .NET SDK, and an editor such as VS Code.\n",
      "    See doc_c_sharp_setup.\n",
      "\n",
      " \n",
      "\n",
      "    The C++ part of this tutorial wasn't rewritten for the new GDExtension system yet.\n",
      "\n",
      "Your project folder should look like this.\n",
      "This game is designed for portrait mode, so we need to adjust the size of the\n",
      "game window. Click on *Project > Project Settings* to open the project settings\n",
      "window, in the left column open the *Display > Window* tab. There, set\n",
      "\"Viewport Width\" to ``480`` and \"Viewport Height\" to ``720``.\n",
      "Also, under the **Stretch** options, set **Mode** to ``canvas_items`` and **Aspect** to ``keep``.\n",
      "This ensures that the game scales consistently on different sized screens.\n",
      "Organizing the project\n",
      "In this project, we will make 3 independent scenes: ``Player``, ``Mob``, and\n",
      "``HUD``, which we will combine into the game's ``Main`` scene.\n",
      "\n",
      "In a larger project, it might be useful to create folders to hold the various\n",
      "scenes and their scripts, but for this relatively small game, you can save your\n",
      "scenes and scripts in the project's root folder, identified by ``res://``. You\n",
      "can see your project folders in the FileSystem dock in the lower left corner:\n",
      "With the project in place, we're ready to design the player scene in the next lesson.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(dataset['document'][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "hf_dataset = Dataset.from_pandas(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['File', 'document'],\n",
       "    num_rows: 1381\n",
       "})"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hf_dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading a pre-trained model to get an understanding of the baseline performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint = \"sentence-transformers/multi-qa-mpnet-base-dot-v1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = AutoModel.from_pretrained(checkpoint)\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(checkpoint)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MPNetModel(\n",
       "  (embeddings): MPNetEmbeddings(\n",
       "    (word_embeddings): Embedding(30527, 768, padding_idx=1)\n",
       "    (position_embeddings): Embedding(514, 768, padding_idx=1)\n",
       "    (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "    (dropout): Dropout(p=0.1, inplace=False)\n",
       "  )\n",
       "  (encoder): MPNetEncoder(\n",
       "    (layer): ModuleList(\n",
       "      (0-11): 12 x MPNetLayer(\n",
       "        (attention): MPNetAttention(\n",
       "          (attn): MPNetSelfAttention(\n",
       "            (q): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (k): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (v): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (o): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (intermediate): MPNetIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (intermediate_act_fn): GELUActivation()\n",
       "        )\n",
       "        (output): MPNetOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (relative_attention_bias): Embedding(32, 12)\n",
       "  )\n",
       "  (pooler): MPNetPooler(\n",
       "    (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "    (activation): Tanh()\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.to(torch.get_default_device())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cls_pooling(model_output):\n",
    "    # print(model_output.last_hidden_state[:,0,:].shape)\n",
    "    return model_output.last_hidden_state[:, 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_embeddings(text_list):\n",
    "    encoded_input = tokenizer(\n",
    "        text_list, padding=True, truncation=True, return_tensors=\"pt\"\n",
    "    )\n",
    "    encoded_input = {k: v.to(torch.get_default_device()) for k, v in encoded_input.items()}\n",
    "    model_output = model(**encoded_input)\n",
    "    # print(model_output.last_hidden_state.shape)\n",
    "    return cls_pooling(model_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|██████████| 1381/1381 [00:43<00:00, 31.41 examples/s]\n"
     ]
    }
   ],
   "source": [
    "embeddings_dataset = hf_dataset.map(\n",
    "    lambda x: {\"embeddings\": get_embeddings(x[\"document\"]).detach().cpu().numpy()[0]}\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2/2 [00:00<00:00, 495.28it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['File', 'document', 'embeddings'],\n",
       "    num_rows: 1381\n",
       "})"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embeddings_dataset.add_faiss_index(column=\"embeddings\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 768)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "question = \"What is an array?\"\n",
    "question_embedding = get_embeddings([question]).cpu().detach().numpy()\n",
    "question_embedding.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores, samples = embeddings_dataset.get_nearest_examples(\n",
    "    \"embeddings\", question_embedding, k=5\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "samples_df = pd.DataFrame.from_dict(samples)\n",
    "samples_df[\"scores\"] = scores\n",
    "samples_df.sort_values(\"scores\", ascending=False, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>File</th>\n",
       "      <th>document</th>\n",
       "      <th>embeddings</th>\n",
       "      <th>scores</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>class_packedvector3array.rst.txt</td>\n",
       "      <td>:github_url: hide\\nPackedVector3Array\\nA packe...</td>\n",
       "      <td>[0.26605814695358276, -0.5201044678688049, -0....</td>\n",
       "      <td>29.815216</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>class_packedfloat64array.rst.txt</td>\n",
       "      <td>:github_url: hide\\nPackedFloat64Array\\nA packe...</td>\n",
       "      <td>[0.00835494790226221, -0.6012332439422607, -0....</td>\n",
       "      <td>29.756012</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>class_packedint64array.rst.txt</td>\n",
       "      <td>:github_url: hide\\nPackedInt64Array\\nA packed ...</td>\n",
       "      <td>[-0.11035095900297165, -0.5851216912269592, -0...</td>\n",
       "      <td>29.539976</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>class_array.rst.txt</td>\n",
       "      <td>:github_url: hide\\nArray\\nA builtin data struc...</td>\n",
       "      <td>[-0.05643428489565849, -0.22368930280208588, -...</td>\n",
       "      <td>27.741829</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>class_packedstringarray.rst.txt</td>\n",
       "      <td>:github_url: hide\\nPackedStringArray\\nA packed...</td>\n",
       "      <td>[0.03704645112156868, -0.43851298093795776, -0...</td>\n",
       "      <td>27.186140</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                               File  \\\n",
       "4  class_packedvector3array.rst.txt   \n",
       "3  class_packedfloat64array.rst.txt   \n",
       "2    class_packedint64array.rst.txt   \n",
       "1               class_array.rst.txt   \n",
       "0   class_packedstringarray.rst.txt   \n",
       "\n",
       "                                            document  \\\n",
       "4  :github_url: hide\\nPackedVector3Array\\nA packe...   \n",
       "3  :github_url: hide\\nPackedFloat64Array\\nA packe...   \n",
       "2  :github_url: hide\\nPackedInt64Array\\nA packed ...   \n",
       "1  :github_url: hide\\nArray\\nA builtin data struc...   \n",
       "0  :github_url: hide\\nPackedStringArray\\nA packed...   \n",
       "\n",
       "                                          embeddings     scores  \n",
       "4  [0.26605814695358276, -0.5201044678688049, -0....  29.815216  \n",
       "3  [0.00835494790226221, -0.6012332439422607, -0....  29.756012  \n",
       "2  [-0.11035095900297165, -0.5851216912269592, -0...  29.539976  \n",
       "1  [-0.05643428489565849, -0.22368930280208588, -...  27.741829  \n",
       "0  [0.03704645112156868, -0.43851298093795776, -0...  27.186140  "
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "samples_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SCORE: 29.815216064453125\n",
      "FILE: class_packedvector3array.rst.txt\n",
      "==================================================\n",
      "\n",
      "SCORE: 29.756011962890625\n",
      "FILE: class_packedfloat64array.rst.txt\n",
      "==================================================\n",
      "\n",
      "SCORE: 29.539976119995117\n",
      "FILE: class_packedint64array.rst.txt\n",
      "==================================================\n",
      "\n",
      "SCORE: 27.74182891845703\n",
      "FILE: class_array.rst.txt\n",
      "==================================================\n",
      "\n",
      "SCORE: 27.186140060424805\n",
      "FILE: class_packedstringarray.rst.txt\n",
      "==================================================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for _, row in samples_df.iterrows():\n",
    "    # print(f\"DOCUMENT: {row.document}\")\n",
    "    print(f\"SCORE: {row.scores}\")\n",
    "    print(f\"FILE: {row.File}\")\n",
    "    print(\"=\" * 50)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Finetuning the base bi-encoder using glaiveai/godot-4-docs dataset from HF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "ds = load_dataset(\"glaiveai/godot_4_docs\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds.set_format(\"torch\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sentence_transformers.losses import MultipleNegativesRankingLoss\n",
    "from sentence_transformers import SentenceTransformer, SentenceTransformerTrainer, SentenceTransformerTrainingArguments, SentenceTransformerModelCardData\n",
    "from sentence_transformers.training_args import BatchSamplers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint = \"sentence-transformers/multi-qa-mpnet-base-dot-v1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = SentenceTransformer(checkpoint)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss = MultipleNegativesRankingLoss(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "args = SentenceTransformerTrainingArguments(\n",
    "    # Required parameter:\n",
    "    output_dir=\"models/multi-qa-mpnet-base-dot-v1\",\n",
    "    # Optional training parameters:\n",
    "    num_train_epochs=1,\n",
    "    per_device_train_batch_size=16,\n",
    "    per_device_eval_batch_size=16,\n",
    "    learning_rate=2e-5,\n",
    "    warmup_ratio=0.1,\n",
    "    fp16=True,  # Set to False if you get an error that your GPU can't run on FP16\n",
    "    bf16=False,  # Set to True if you have a GPU that supports BF16\n",
    "    batch_sampler=BatchSamplers.NO_DUPLICATES,  # losses that use \"in-batch negatives\" benefit from no duplicates\n",
    "    # Optional tracking/debugging parameters:\n",
    "    eval_strategy=\"no\",\n",
    "    eval_steps=100,\n",
    "    save_strategy=\"steps\",\n",
    "    save_steps=100,\n",
    "    save_total_limit=2,\n",
    "    logging_steps=100,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = SentenceTransformerTrainer(\n",
    "    model=model,\n",
    "    args=args,\n",
    "    train_dataset=ds,\n",
    "    loss=loss,\n",
    ")\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 8. Save the trained model\n",
    "model.save_pretrained(\"models/multi-qa-mpnet-glaive-godotdocs-dot/final\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 9. (Optional) Push it to the Hugging Face Hub\n",
    "model.push_to_hub(\"multi-qa-mpnet-glaive-godotdocs-dot\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "ft_model = AutoModel.from_pretrained('models/multi-qa-mpnet-glaive-godotdocs-dot/final')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "ft_tokenizer = AutoTokenizer.from_pretrained('models/multi-qa-mpnet-glaive-godotdocs-dot/final')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Performing a semantic search on godot docs with the finetuned docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cls_pooling(model_output):\n",
    "    # print(model_output.last_hidden_state[:,0,:].shape)\n",
    "    return model_output.last_hidden_state[:, 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_embeddings_ft(text_list):\n",
    "    encoded_input = ft_tokenizer(\n",
    "        text_list, padding=True, truncation=True, return_tensors=\"pt\"\n",
    "    )\n",
    "    encoded_input = {k: v.to(torch.get_default_device()) for k, v in encoded_input.items()}\n",
    "    model_output = ft_model(**encoded_input)\n",
    "    # print(model_output.last_hidden_state.shape)\n",
    "    return cls_pooling(model_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|██████████| 1381/1381 [00:44<00:00, 30.94 examples/s]\n"
     ]
    }
   ],
   "source": [
    "embeddings_dataset = hf_dataset.map(\n",
    "    lambda x: {\"embeddings\": get_embeddings_ft(x[\"document\"]).detach().cpu().numpy()[0]}\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2/2 [00:00<00:00, 468.22it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['File', 'document', 'embeddings'],\n",
       "    num_rows: 1381\n",
       "})"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embeddings_dataset.add_faiss_index(column=\"embeddings\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 768)"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "question = \"How do I write a vertex shader to mimic ps1 look?\"\n",
    "question_embedding = get_embeddings([question]).cpu().detach().numpy()\n",
    "question_embedding.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores, samples = embeddings_dataset.get_nearest_examples(\n",
    "    \"embeddings\", question_embedding, k=5\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "samples_df = pd.DataFrame.from_dict(samples)\n",
    "samples_df[\"scores\"] = scores\n",
    "samples_df.sort_values(\"scores\", ascending=False, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>File</th>\n",
       "      <th>document</th>\n",
       "      <th>embeddings</th>\n",
       "      <th>scores</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>compute_shaders.rst.txt</td>\n",
       "      <td>\\nUsing compute shaders\\nThis tutorial will wa...</td>\n",
       "      <td>[-0.040888749063014984, -0.1411910355091095, -...</td>\n",
       "      <td>53.245289</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>class_visualshader.rst.txt</td>\n",
       "      <td>:github_url: hide\\nVisualShader\\n**Inherits:**...</td>\n",
       "      <td>[0.028908975422382355, -0.14371901750564575, -...</td>\n",
       "      <td>52.143013</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>class_color.rst.txt</td>\n",
       "      <td>:github_url: hide\\nColor\\nA color represented ...</td>\n",
       "      <td>[0.006059261970221996, -0.21860522031784058, -...</td>\n",
       "      <td>51.480659</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>shaders_style_guide.rst.txt</td>\n",
       "      <td>\\nShaders style guide\\nThis style guide lists ...</td>\n",
       "      <td>[0.35104429721832275, 0.028790568932890892, -0...</td>\n",
       "      <td>51.431374</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>class_gradienttexture1d.rst.txt</td>\n",
       "      <td>:github_url: hide\\nGradientTexture1D\\n**Inheri...</td>\n",
       "      <td>[0.22399283945560455, -0.2904146909713745, -0....</td>\n",
       "      <td>51.217575</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                              File  \\\n",
       "4          compute_shaders.rst.txt   \n",
       "3       class_visualshader.rst.txt   \n",
       "2              class_color.rst.txt   \n",
       "1      shaders_style_guide.rst.txt   \n",
       "0  class_gradienttexture1d.rst.txt   \n",
       "\n",
       "                                            document  \\\n",
       "4  \\nUsing compute shaders\\nThis tutorial will wa...   \n",
       "3  :github_url: hide\\nVisualShader\\n**Inherits:**...   \n",
       "2  :github_url: hide\\nColor\\nA color represented ...   \n",
       "1  \\nShaders style guide\\nThis style guide lists ...   \n",
       "0  :github_url: hide\\nGradientTexture1D\\n**Inheri...   \n",
       "\n",
       "                                          embeddings     scores  \n",
       "4  [-0.040888749063014984, -0.1411910355091095, -...  53.245289  \n",
       "3  [0.028908975422382355, -0.14371901750564575, -...  52.143013  \n",
       "2  [0.006059261970221996, -0.21860522031784058, -...  51.480659  \n",
       "1  [0.35104429721832275, 0.028790568932890892, -0...  51.431374  \n",
       "0  [0.22399283945560455, -0.2904146909713745, -0....  51.217575  "
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "samples_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SCORE: 53.24528884887695\n",
      "FILE: compute_shaders.rst.txt\n",
      "==================================================\n",
      "\n",
      "SCORE: 52.14301300048828\n",
      "FILE: class_visualshader.rst.txt\n",
      "==================================================\n",
      "\n",
      "SCORE: 51.48065948486328\n",
      "FILE: class_color.rst.txt\n",
      "==================================================\n",
      "\n",
      "SCORE: 51.431373596191406\n",
      "FILE: shaders_style_guide.rst.txt\n",
      "==================================================\n",
      "\n",
      "SCORE: 51.21757507324219\n",
      "FILE: class_gradienttexture1d.rst.txt\n",
      "==================================================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for _, row in samples_df.iterrows():\n",
    "    # print(f\"DOCUMENT: {row.document}\")\n",
    "    print(f\"SCORE: {row.scores}\")\n",
    "    print(f\"FILE: {row.File}\")\n",
    "    print(\"=\" * 50)\n",
    "    print()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nlpia_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
